# -*- coding: utf-8 -*-
"""Statistics_Abeokuta Training

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kZnVdUaVx52JhM9-ul549WUcuvigkVNW

# ***INTRODUCTION TO STATISTICS***


Welcome to this study on **Statistics for Data Science**!

In this journey, we'll dive into key statistical concepts that are essential for AI and Machine Learning. We'll start with foundational concepts and progressively tackle more advanced topics, including probability, statistical inference, hypothesis testing, and regression.

This notebook covers:
- **Measures of Center**
- **Measures of Spread**

## Introduction

What is Statistics?

- Statistics is the study of how to collect, analyze, and draw conclusions from data. It’s a hugely valuable tool that you can use to bring the future into focus and infer the answer to tons of questions. For example, what is the likelihood of someone purchasing your product,  how many jeans sizes should you manufacture to fit 95% of the population? Statistics can be used to answer lots of different types of questions, but being able to identify which type of statistics is needed is essential to drawing accurate conclusions.

- Summary statisics generally discusses or gives insights to the summary of your data.

There are 2 types of Statistics namely; Descriptive and Inferrential Statistics.

- Descriptive Statistics describes and summarizes our data.

- While inferrential statistics in essential in making inferences and drawing conclusions about our data.


[<img src="https://drive.google.com/uc?id=1nD0D1tIX1gZtqggMmg5-YFpwb2oFKwvA" alt="Image Description" width="800"/>](https://github.com/anhhaibkhn/Data-Science-selfstudy-notes-Blog/blob/master/_notebooks/Introduction%20to%20Statistics%20in%20Python/pdfs/chapter1.pdf)
"""

!pip install gdown
import gdown

file_id = '1yB5qSBOLl96Y563nIewKOU8RN_gsY3dO'  # Make sure it's a string
gdown.download(f'https://drive.google.com/uc?id={file_id}', 'data.csv', quiet=False)

import pandas as pd
import numpy as np

# Read the downloaded CSV file
df = pd.read_csv('data.csv')
df.head()

"""## Measures of Center

Measures of center are statistical values that describe the central tendency of a dataset. They provide a summary measure that represents the entire dataset, allowing you to understand where the majority of your data points lie. Understanding these measures help to summarize and describe data effectively.

### 1. Mean

- The **mean**, often referred to as the average, is calculated by summing all the values in a dataset and dividing by the number of values. It is a commonly used measure of center.
  
  **Formula:**

$$
\text{Mean} (\mu) = \frac{\sum_{i=1}^{n} x_i}{n}
$$

**Where:**
- \( $x_i$ \) represents each value in the dataset.
- \( $n$ \) is the total number of values.

**Example:**
For the dataset [5, 10, 15, 20] \:

$$
\text{Mean} = \frac{5 + 10 + 15 + 20}{4} = \frac{50}{4} = 12.5
$$



- **Considerations:** The mean can be influenced by outliers. For instance, in the dataset [1, 2, 3, 100] \, the mean is significantly higher than most data points due to the outlier "100".

### 2. Median

- The **median** is the middle value when the dataset is ordered from least to greatest. If the dataset has an even number of observations, the median is the average of the two middle values. The median is a robust measure of center that is less affected by outliers.
  
  **Steps to Calculate Median:**
  1. Sort the data in ascending order.
  2. If the number of observations \($n$\) is odd, the median is the middle number.
  3. If \($n$\) is even, the median is the average of the two middle numbers.

  **Example:**

  For the dataset  [1, 3, 6, 3, 7, 9, 8] \:
  - Sorted: [1, 3, 3, 6, 7, 8, 9] \
  - The Median is $6$, the $4th$ value

  For the dataset [1, 2, 3, 5, 4, 6]:
  - Sorted: [1, 2, 3, 4, 5, 6] \
  - The Median is:
    $$
    \text{Median} = \frac{3 + 4}{2} = 3.5
    $$

### 3. Mode

- The **mode** is the value that appears most frequently in a dataset. A dataset may have one mode, more than one mode (bimodal or multimodal), or no mode at all if all values occur with the same frequency.

- **Example:** For the dataset [1, 2, 2, 3, 4] \:
  - Mode: \( $2$ \)

  For the dataset [1, 1, 2, 2, 3, 4] \:
  - The Modes are \( $1$ \) and \( $2$ \)  $i.e$, bimodal



### Summary of Measures of Center

- **Mean:** Sensitive to outliers, best for symmetric/normal distributions.
- **Median:** Robust against outliers, represents the center in skewed distributions.
- **Mode:** Useful for categorical data, indicates the most common value.




Understanding the measures of center is important in Data Science to help summarize data with a single representative value. They assist in comparing different datasets, understanding trends, and making informed decisions based on data.

[<img src="https://drive.google.com/uc?id=1fYdyU8Ris_FP1FFD_6ianuo8LgNSmJ68" alt="Measures of Center" width="600"/>](https://www.google.com/url?sa=i&url=https%3A%2F%2Ftowardsai.net%2Fp%2Fl%2Fpython-statistical-analysis-measures-of-central-tendency-and-dispersion&psig=AOvVaw3eoQpaEtgizlksZ5lHMCZQ&ust=1730369714671000&source=images&cd=vfe&opi=89978449&ved=0CBQQjRxqFwoTCPij1dTvtYkDFQAAAAAdAAAAABAE)


"""

df



df.drop('Unnamed: 0', axis = 1, inplace = True)

df

df.describe(include = 'all')

be_consumption =df[df['country'] == 'Belgium']

be_consumption

be_consume=be_consumption['consumption']

# Calculate mean and median consumption in Belgium

print(np.mean(be_consume))

print(np.median(be_consume))

# Filter for USA
usa_consumption = df[df['country'] == 'USA']

usa_consumption

us_consume = usa_consumption['consumption']

us_consume

# Calculate mean and median consumption in USA
print(np.mean(us_consume))

print(np.median(us_consume))

df['country'].value_counts()

# Check the mode of the country column
mode_country = df['country'].mode()

print("Mode Country:", mode_country)

"""### Measures of Spread"""

df

"""## Measures of Spread

Measures of spread, also known as measures of variability or dispersion, are statistical tools that describe how much the values in a dataset differ from each other and from the center, i.e., the mean. Understanding these measures enables us to interpret the distribution and consistency of the data. In other words, they show us how "spread out" or "concentrated" the data points are.
[<img src="https://drive.google.com/uc?id=1Gw2Lx5IN5_mTA7j5OVlBBeXtd1NgEUsg" alt="Measures of Center" width="600"/>](https://www.youtube.com/watch?v=-zUKM_AjKts)


Some example use cases of measures of spread include:

- Evaluating the consistency of test scores among students.
- Analyzing the variability in sales data over time.
- Assessing the risk and return in investment portfolios.

Key measures of spread include:

### 1. Variance

- **Definition**: Variance measures how far a set of numbers is from their average value i.e mean. It calculates the average of the squared differences from the mean and provides insight into the degree of dispersion or spread in the dataset. It seeks to answer the question: How wide do the individual data points vary from the mean of the dataset? A higher variance indicates that the data points are more spread out from the mean (Outliers), while a lower variance suggests that the data points are closer to the mean.

- **Importance**: Variance is important because it provides a mathematical basis for standard deviation and can give first hand insight into the presence of outlier.

- **Formula**:
  $$
  \text{Variance} (\sigma^2) = \frac{\sum_{i=1}^{n} (x_i - \mu)^2}{n}
  $$

- **Example**: Using the previous dataset [4, 8, 6, 5, 3] \, the variance will be giving us:
  $$
  \text{Variance} = 2.96
  $$


### 2. Standard Deviation(Std)

- **Definition**: Standard deviation is a measure that quantifies the amount of variation or dispersion in a set of values. A low standard deviation indicates that the data points tend to be close to the mean, while a high standard deviation suggests that the data points are spread out over a larger range of values (Outliers). It is simply the squareroot of the variance

- **Importance**: Standard deviation helps you understand how consistent or reliable your data is. For instance, if you're measuring test scores, a low standard deviation means that most students scored similarly, while a high standard deviation means that scores varied widely.

- **Formula**:
  $$
  \text{Standard Deviation} (\sigma) = \sqrt{\frac{\sum_{i=1}^{n} (x_i - \mu)^2}{n}}
  $$
  Where:
  - \($x_i$\) is each observation,
  - \($\mu$\) is the mean of the dataset,
  - \($n\$) is the total number of values.

- **Example**: Let's calculate the standard deviation for the dataset [4, 8, 6, 5, 3] \:
  1. **Calculate the Mean**:
     $$
     \mu = \frac{4 + 8 + 6 + 5 + 3}{5} = 5.2
     $$
  2. **Calculate the Variance** (the average of the squared differences from the mean):
     $$
     \text{Variance} = \frac{(4 - 5.2)^2 + (8 - 5.2)^2 + (6 - 5.2)^2 + (5 - 5.2)^2 + (3 - 5.2)^2}{5} = \frac{(1.44 + 7.84 + 0.64 + 0.04 + 4.84)}{5} = \frac{14.8}{5} = 2.96
     $$
  3. **Finally, calculate the Standard Deviation**:
     $$
     \sigma = \sqrt{2.96} \approx 1.72
     $$
     [<img src="https://drive.google.com/uc?id=1zrVBK94AQ9c5ILPmTjzpF-wLEl_59vEl" alt="Measures of Center" width="500"/>](https://stats.stackexchange.com/questions/476677/understanding-standard-deviation-in-normal-distribution)

### 3. Range

- **Definition**: The range is the simplest measure of spread and is calculated as the difference between the maximum and minimum values in a dataset.

- **Importance**: The range gives a quick sense of the spread of the data but can be heavily influenced by outliers.

- **Formula**:
  $$
  \text{Range} = \text{Max} - \text{Min}
  $$

- **Example**: For the dataset $[4, 8, 6, 5, 3] \$:
  $$
  \text{Range} = 8 - 3 = 5
  $$


### 4. Percentiles


- **Definition**: Percentiles are values that divide a dataset into 100 equal parts. The \$k\$-th percentile is the value below which $k$% of the data falls.

- **Importance**: Percentiles provide insights into the relative standing of data points within a dataset and helps to identify the distribution of values.
- **Example**: The $50th$ percentile is the median, which divides the data into two equal halves.

[<img src="https://drive.google.com/uc?id=1cBTbSiYMcn_3555vRpoHUOp6l2p12nFO" alt="Measures of Center" width="500"/>](https://www.timescale.com/blog/how-percentiles-work-and-why-theyre-better-than-averages/)

### 5. Interquartile Range (IQR)

- **Definition**: The interquartile range is a measure of statistical dispersion that describes the range within which  50% of the data points lie/fall. It is calculated as the difference between the third quartile ($Q3$) and the first quartile ($Q1$).

- **Importance**: IQR is a robust measure of spread that is less affected by outliers than the range. It helps to identify the middle spread of the data.

- **Formula**:
  $$
  \text{IQR} = Q_3 - Q_1
  $$
  Where:
  - $Q_1$ is the first quartile 25th percentile,
  - $Q_3$ is the third quartile 75th percentile.

### 6. Skewness

- **Definition**: Skewness measures the asymmetry of the distribution of values in a dataset. It tells you whether the data points are skewed/drawn to the left or right of the mean. A skewness value of zero indicates a symmetric distribution.

- **Types of Skewness**:
  - **Positive Skewness**: The Tail is on the right side (data is skewed to the right). The mean is greater than the median.
  - **Negative Skewness**: Tail on the left side (data is skewed to the left). The mean is less than the median.

  [<img src="https://drive.google.com/uc?id=1ZJxwOGApc_IIi0aWltdxDpFSXNlOmIvx" alt="Measures of Center" width="500"/>](https://medium.com/@dhaval.sony.504/everything-you-should-know-about-skewness-c5edf381cc6d)

- **Formula**:
  $$
  \text{Skewness} = \frac{n}{(n-1)(n-2)} \sum_{i=1}^{n} \left(\frac{x_i - \mu}{\sigma}\right)^3
  $$

- **Example**: To calculate the skewness of the dataset $[1, 2, 2, 3, 10] \$:
  1. Calculate the mean μ and standard deviation σ.
  2. Substitute  them into the skewness formula. You would find a positive skewness value indicating that the data is skewed to the right due to the presence of the outlier "10".

### 7. Kurtosis

- **Definition**: Kurtosis is a statistical measure that describes the distribution of data points in the tails relative to the overall distribution. It provides insights into the "tailedness" of the distribution. High kurtosis indicates heavy tails and a sharp peak (more outliers), while low kurtosis indicates light tails and a flatter peak.


[<img src="https://drive.google.com/uc?id=16I8oJe6AC77-Fk_5JWi-KCoRYGrgSSS9" alt="Measures of Center" width="500"/>](https://www.scribbr.com/statistics/kurtosis/)

- **Types of Kurtosis**:
  - **Leptokurtic**: Has High kurtosis (>3) - Data with heavy tails and a sharper peak, indicating potential outliers.
  - **Mesokurtic**: Normal distribution (≈3) - Data with moderate tails, resembling a normal distribution.
  - **Platykurtic**: Low kurtosis (<3) - Data with light tails and a flatter peak, suggesting fewer outliers.

- **Formula**:
  $$
  \text{Kurtosis} = \frac{n(n+1)}{(n-1)(n-2)(n-3)} \sum_{i=1}^{n} \left(\frac{x_i - \mu}{\sigma}\right)^4 - \frac{3(n-1)^2}{(n-2)(n-3)}
  $$

- **Example**: For a dataset  [1, 2, 3, 4, 5] , you can compute the kurtosis by substituting values into the formula.
PS: calculating kurtosis typically requires statistical software for larger datasets.

Understanding measures of spread is crucial for effectively interpreting data distributions. These measures help understand the variability, consistency, and overall characteristics of datasets. Measures like kurtosis and skewness, while often discussed in the context of spread, are more accurately described as measures of shape, as they provide detail into the distribution's characteristics rather than its variability alone.

Let's Practice
"""

co2_min = df['co2_emission'].min()  # Minimum value

co2_min

co2_max = df['co2_emission'].max()  # Maximum value

co2_max

co2_range = co2_max - co2_min       # Calculate range

print("CO2 Emission Range:", co2_range)

df.describe()

df['co2_emission'].var()

df['co2_emission'].std()

percentiles = df['co2_emission'].quantile([0.10, 0.25, 0.50, 0.75])

print("Percentiles:\n", percentiles)

iqr = percentiles[0.75] - percentiles[0.25]

print("Interquartile Range (IQR):", iqr)

print("Percentiles:\n", list(percentiles))

iqr = list(percentiles)[3] - list(percentiles)[1]

print("Interquartile Range (IQR):", iqr)

skewness = df['co2_emission'].skew()

print("Skewness:", skewness)

import matplotlib.pyplot as plt
import seaborn as sns

data = df['co2_emission']

# Calculate statistics
mean_val = data.mean()
median_val = data.median()
mode_val = data.mode()[0]
skewness = data.skew()

# Plot histogram with KDE
plt.figure(figsize=(10,6))
sns.histplot(data, bins=30, kde=True, color="purple")

# Add vertical lines
plt.axvline(mean_val, color='green', linestyle='--', linewidth=2, label=f'Mean = {mean_val:.2f}')
plt.axvline(median_val, color='grey', linestyle='-', linewidth=2, label=f'Median = {median_val:.2f}')
plt.axvline(mode_val, color='red', linestyle=':', linewidth=2, label=f'Mode = {mode_val:.2f}')

# Add title and skewness
plt.title(f"CO2 Emission Distribution (Skewness = {skewness:.2f})", fontsize=14)
plt.xlabel("CO2 Emission")
plt.ylabel("Frequency")
plt.legend()

plt.show()

kurtosis = df['co2_emission'].kurtosis()

print("Kurtosis:", kurtosis)

"""### Detecting Outliers"""

